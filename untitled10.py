# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uqo2vZkHSXxdWKpON_X6Lb336-oMYViz
"""

# app/data_fetcher.py
"""
Discover and download datasets from data.gov.in (CKAN).
This module contains:
 - search_packages(query): finds candidate packages via CKAN package_search
 - download_resource_csv(resource_url): attempts to download a CSV resource and return a pandas.DataFrame
"""

import requests
import pandas as pd
from io import BytesIO
import logging

CKAN_SEARCH = "https://data.gov.in/api/3/action/package_search"

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def search_packages(query, rows=10):
    """Search data.gov.in CKAN for packages matching query."""
    params = {"q": query, "rows": rows}
    r = requests.get(CKAN_SEARCH, params=params, timeout=30)
    r.raise_for_status()
    res = r.json()
    return res.get("result", {}).get("results", [])

def download_resource_csv(resource_url, timeout=60):
    """Download a CSV resource URL and return a pandas DataFrame.
       Handles common cases where resource_url points to CSV or zipped CSV.
    """
    logger.info("Downloading resource: %s", resource_url)
    r = requests.get(resource_url, timeout=timeout)
    r.raise_for_status()
    content_type = r.headers.get('Content-Type', '').lower()
    content = r.content

    # Try reading directly as CSV
    try:
        df = pd.read_csv(BytesIO(content))
        return df
    except Exception:
        # fallback: try with pandas' read_table with encoding guesses
        try:
            df = pd.read_table(BytesIO(content), sep=',', engine='python')
            return df
        except Exception as e:
            logger.error("Failed to parse resource as CSV: %s", e)
            raise

# Example helper to inspect candidate resources for a package:
def list_package_resources(package):
    """Return list of resource dicts for a package result from search_packages."""
    return package.get('resources', [])

# app/normalizer.py
"""
Simple normalization utilities:
 - canonicalize state names (basic)
 - canonicalize crop names (basic)
 - ensure numeric columns and year parsing
For production use, extend with fuzzy matching (fuzzywuzzy / rapidfuzz).
"""

import pandas as pd

STATE_SYNONYMS = {
    "tn": "Tamil Nadu",
    "tamil nadu": "Tamil Nadu",
    "karnataka": "Karnataka",
    "ka": "Karnataka",
    # add more mappings as needed
}

CROP_SYNONYMS = {
    "paddy": "Rice",
    "rice (paddy)": "Rice",
    "rice": "Rice",
    "wheat": "Wheat",
    # add more mappings
}

def canonical_state(name):
    if pd.isna(name):
        return name
    s = str(name).strip().lower()
    return STATE_SYNONYMS.get(s, name)

def canonical_crop(name):
    if pd.isna(name):
        return name
    s = str(name).strip().lower()
    return CROP_SYNONYMS.get(s, name)

def normalize_rainfall_df(df, state_col='state', year_col='year', rainfall_col='rainfall_mm'):
    df = df.copy()
    df[state_col] = df[state_col].apply(canonical_state)
    df[year_col] = pd.to_numeric(df[year_col], errors='coerce').astype('Int64')
    df[rainfall_col] = pd.to_numeric(df[rainfall_col], errors='coerce')
    return df

def normalize_crop_df(df, state_col='state', year_col='year', crop_col='crop', prod_col='production_tonnes'):
    df = df.copy()
    df[state_col] = df[state_col].apply(canonical_state)
    df[crop_col] = df[crop_col].apply(canonical_crop)
    df[year_col] = pd.to_numeric(df[year_col], errors='coerce').astype('Int64')
    df[prod_col] = pd.to_numeric(df[prod_col], errors='coerce')
    return df

# app/qna_engine.py
"""
Small rule-based QnA engine that uses normalized dataframes to answer a
few canonical intents:
 - compare_rainfall_and_top_crops
 - district_max_min_crop
 - trend_and_correlation
The functions return both result and provenance info (dataset name / filter).
"""

import pandas as pd
from typing import Dict, Any

def compare_rainfall_and_top_crops(df_rain: pd.DataFrame, df_crop: pd.DataFrame,
                                   state_x: str, state_y: str, n_years: int = 5, top_m: int = 3):
    # Compute available years intersection (use latest n_years from rainfall dataset)
    years = sorted(df_rain['year'].dropna().unique())
    if len(years)==0:
        raise ValueError("No years found in rainfall dataframe")
    years = years[-n_years:]
    # filter
    r_x = df_rain[(df_rain['state']==state_x) & (df_rain['year'].isin(years))]
    r_y = df_rain[(df_rain['state']==state_y) & (df_rain['year'].isin(years))]
    avg_x = float(r_x['rainfall_mm'].mean()) if not r_x.empty else None
    avg_y = float(r_y['rainfall_mm'].mean()) if not r_y.empty else None

    # crops: sum production across the same years
    c_x = (df_crop[(df_crop['state']==state_x) & (df_crop['year'].isin(years))]
           .groupby('crop')['production_tonnes'].sum().nlargest(top_m))
    c_y = (df_crop[(df_crop['state']==state_y) & (df_crop['year'].isin(years))]
           .groupby('crop')['production_tonnes'].sum().nlargest(top_m))

    # convert to serializable dicts
    top_x = c_x.reset_index().to_dict(orient='records') if not c_x.empty else []
    top_y = c_y.reset_index().to_dict(orient='records') if not c_y.empty else []

    provenance = {
        "rainfall_dataset": {
            "title": "IMD Rainfall (area-weighted monthly/annual) - data.gov.in",
            "filter": {"states": [state_x, state_y], "years": list(years)}
        },
        "crop_dataset": {
            "title": "District-wise, season-wise crop production statistics - data.gov.in",
            "filter": {"states": [state_x, state_y], "years": list(years)}
        }
    }

    return {
        "avg_rainfall": {state_x: avg_x, state_y: avg_y},
        "top_crops": {state_x: top_x, state_y: top_y},
        "years_considered": list(years),
        "provenance": provenance
    }

def district_max_min_crop(df_crop: pd.DataFrame, state_x: str, state_y: str, crop_z: str, latest_year=None):
    # Determine latest_year if not provided
    years = sorted(df_crop['year'].dropna().unique())
    if latest_year is None:
        latest_year = years[-1] if len(years)>0 else None
    if latest_year is None:
        raise ValueError("No year information available in crop df.")
    # filter by year and crop
    dfy = df_crop[(df_crop['year']==latest_year) & (df_crop['crop']==crop_z)]
    if dfy.empty:
        return {"error": "No data for this crop/year combination", "provenance": {}}
    max_x = dfy[dfy['state']==state_x].nlargest(1, 'production_tonnes')
    min_y = dfy[dfy['state']==state_y].nsmallest(1, 'production_tonnes')
    prov = {
        "crop_dataset": {
            "title": "District-wise, season-wise crop production statistics - data.gov.in",
            "filter": {"crop": crop_z, "year": latest_year, "states": [state_x, state_y]}
        }
    }
    return {
        "latest_year": int(latest_year),
        "state_x_max": max_x.to_dict(orient='records'),
        "state_y_min": min_y.to_dict(orient='records'),
        "provenance": prov
    }

def trend_and_correlation(df_crop: pd.DataFrame, df_rain: pd.DataFrame, region: str, crop_type: str, years_back:int=10):
    # compute time series and correlation (Pearson)
    yrs_crop = sorted(df_crop[df_crop['state']==region]['year'].dropna().unique())
    yrs_rain = sorted(df_rain[df_rain['state']==region]['year'].dropna().unique())
    common_years = sorted(list(set(yrs_crop).intersection(set(yrs_rain))))
    if not common_years:
        return {"error": "No overlapping years for region in datasets", "provenance": {}}
    # limit to last years_back
    common_years = sorted(common_years)[-years_back:]
    crop_ts = (df_crop[(df_crop['state']==region) & (df_crop['crop']==crop_type) & (df_crop['year'].isin(common_years))]
               .groupby('year')['production_tonnes'].sum().reindex(common_years, fill_value=0))
    rain_ts = (df_rain[(df_rain['state']==region) & (df_rain['year'].isin(common_years))]
               .groupby('year')['rainfall_mm'].mean().reindex(common_years, fill_value=0))
    corr = None
    try:
        corr = float(crop_ts.corr(rain_ts))
    except Exception:
        corr = None
    prov = {
        "rainfall_dataset": {"title": "IMD Rainfall - data.gov.in", "filter": {"region": region, "years": common_years}},
        "crop_dataset": {"title": "District-wise, season-wise crop production statistics - data.gov.in", "filter": {"region": region, "crop": crop_type, "years": common_years}}
    }
    return {
        "years": common_years,
        "crop_timeseries": crop_ts.reset_index().to_dict(orient='records'),
        "rain_timeseries": rain_ts.reset_index().to_dict(orient='records'),
        "pearson_correlation": corr,
        "provenance": prov
    }

import pandas as pd
import requests
url = "https://data.gov.in/node/135611/datastore/export-csv"
r = requests.get(url, verify=False)  # disable SSL check
open("rainfall_india.csv", "wb").write(r.content)

# app/streamlit_app.py
import streamlit as st
import pandas as pd
from app.normalizer import normalize_rainfall_df, normalize_crop_df
from app.qna_engine import compare_rainfall_and_top_crops

st.set_page_config(page_title="Project Samarth - Gov Data Q&A", layout="wide")
st.title("Project Samarth â€” Q&A over data.gov.in (Agriculture + Climate)")
st.markdown("Demo: compare rainfall and top crops between two states. Results include provenance.")

st.sidebar.header("Demo inputs")
state_x = st.sidebar.text_input("State X", "Karnataka")
state_y = st.sidebar.text_input("State Y", "Tamil Nadu")
n_years = st.sidebar.number_input("Last N years", min_value=1, max_value=20, value=3)
top_m = st.sidebar.number_input("Top M crops", min_value=1, max_value=10, value=3)

st.markdown("**Note:** This demo uses small cached CSV fixtures for speed. For live data, the app can call data.gov.in CKAN and download resources (see `app/data_fetcher.py`).")

if st.button("Run demo: Compare rainfall & top crops"):
    # Load local example fixtures
    df_rain = pd.read_csv("data/example_rainfall_state.csv")
    df_crop = pd.read_csv("data/example_crop_state.csv")
    df_rain = normalize_rainfall_df(df_rain, state_col='state', year_col='year', rainfall_col='rainfall_mm')
    df_crop = normalize_crop_df(df_crop, state_col='state', year_col='year', crop_col='crop', prod_col='production_tonnes')

    ans = compare_rainfall_and_top_crops(df_rain, df_crop, state_x, state_y, n_years, top_m)

    st.subheader("Average annual rainfall")
    st.write(ans['avg_rainfall'])
    st.subheader("Top crops by production (aggregated over selected years)")
    st.write("State: " + state_x)
    st.table(pd.DataFrame(ans['top_crops'][state_x]))
    st.write("State: " + state_y)
    st.table(pd.DataFrame(ans['top_crops'][state_y]))

    with st.expander("Citations & Provenance (click to expand)"):
        prov = ans.get('provenance', {})
        st.json(prov)
        st.markdown("""**Datasets (examples):**
- IMD Rainfall dataset â€” data.gov.in (search: 'Rainfall in India').""")